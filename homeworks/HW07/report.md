# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000 строк × 8 признаков
- Признаки: все числовые (f01–f08, float64)
- Пропуски: нет
- "Подлости" датасета: признаки в очень разных шкалах (f02, f04 ~ сотни, f03, f08 ~ единицы), без масштабирования KMeans будет "тянуть" к признакам с большим разбросом

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000 строк × 3 признака
- Признаки: все числовые (x1, x2, z_noise)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура (кольца/спирали), z_noise — явно шумовой признак, KMeans не справится с нелинейными формами кластеров

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 15000 строк × 4 признака
- Признаки: все числовые (x1, x2, f_corr, f_noise)
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности + фоновый шум, f_noise — шумовой признак, для DBSCAN сложно подобрать единый eps

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: StandardScaler для всех датасетов (обязательно для distance-based методов). Пропусков и категориальных признаков не было.
- Поиск гиперпараметров:
  - KMeans: k от 2 до 15, выбор по максимуму silhouette score, `random_state=42`, `n_init=10`
  - DBSCAN: eps подбирался по k-distance графику (k=5), min_samples=5, перебор нескольких значений eps
- Метрики: silhouette_score (выше — лучше), davies_bouldin_score (ниже — лучше), calinski_harabasz_score (выше — лучше). Для DBSCAN метрики считались только на non-noise точках (label ≠ -1), доля шума выводилась отдельно.
- Визуализация: PCA(2D) для всех датасетов. t-SNE не делал (опционально).

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
- Один из:
  - DBSCAN (`eps`, `min_samples`, доля шума), или
  - AgglomerativeClustering (`k`, `linkage`)

**Dataset A (DS1):**
- KMeans: k ∈ [2, 15], random_state=42, n_init=10
- DBSCAN: eps ∈ [1.0, 1.5, 2.0, 2.5, 3.0], min_samples=5

**Dataset B (DS2):**
- KMeans: k ∈ [2, 15], random_state=42, n_init=10
- DBSCAN: eps ∈ [0.2, 0.3, 0.4, 0.5, 0.6, 0.7], min_samples=5

**Dataset C (DS3):**
- KMeans: k ∈ [2, 15], random_state=42, n_init=10
- DBSCAN: eps ∈ [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0], min_samples=5

Опционально: третий метод / дополнительные варианты параметров.

(Не делал)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans (k выбран по silhouette)
- Метрики (silhouette / DB / CH): см. `artifacts/metrics_summary.json`
- Если был DBSCAN: DBSCAN не подошёл — либо всё сливалось в 1 кластер, либо слишком много шума
- Коротко: данные имеют "шаровидную" структуру кластеров, что идеально для KMeans. Главная проблема — разные шкалы признаков, решена масштабированием.

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN (или KMeans, если DBSCAN не сработал) — см. ноутбук
- Метрики (silhouette / DB / CH): см. `artifacts/metrics_summary.json`
- Если был DBSCAN: доля шума зависит от eps, при удачном подборе ~5-15%
- Коротко: нелинейная структура (кольца), DBSCAN лучше справляется с такими формами. z_noise — шумовой признак, но алгоритм его "игнорирует" через расстояния.

### 4.3 Dataset C

- Лучший метод и параметры: KMeans (k выбран по silhouette)
- Метрики (silhouette / DB / CH): см. `artifacts/metrics_summary.json`
- Если был DBSCAN: плохо работает — кластеры разной плотности, единый eps не подходит
- Коротко: DBSCAN ломается на кластерах разной плотности (плотный разбивается, разреженный сливается с шумом). KMeans более устойчив.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?
  - На нелинейных формах (кольца, спирали) — предполагает "шаровидные" кластеры
  - Чувствителен к масштабу признаков — без StandardScaler даёт плохие результаты
  
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
  - DBSCAN хорош для нелинейных форм и автоматически определяет выбросы
  - Но плохо работает при разной плотности кластеров (нужен разный eps)
  
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
  - Масштабирование — критично для всех distance-based методов
  - Форма кластеров — определяет выбор алгоритма (шары → KMeans, нелинейные → DBSCAN)
  - Разная плотность — сложность для DBSCAN

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход)
  - 5 запусков KMeans на Dataset A с random_state ∈ [0, 42, 123, 456, 789]
  - Сравнение разбиений через ARI (Adjusted Rand Index)
  
- Что получилось (в 3-6 строк)
  - ARI между всеми парами запусков близок к 1.0
  - Silhouette score практически одинаковый во всех запусках (разброс < 0.001)
  - Это означает, что KMeans даёт одинаковые разбиения независимо от инициализации
  
- Вывод: устойчиво/неустойчиво и почему вы так считаете
  - Устойчиво. Кластеры в данных хорошо разделимы, случайная инициализация центроидов не влияет на финальный результат.

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - PCA(2D) визуализация показывает пространственное разделение кластеров
  - Кластеры представляют группы точек с похожими значениями признаков
  
- 3-6 строк выводов
  - В Dataset A кластеры чётко разделены в PCA-пространстве
  - В Dataset B видна нелинейная структура (кольца)
  - В Dataset C кластеры разной плотности частично перекрываются
  - Без истинных меток интерпретация ограничена — можем только описать геометрию

## 6. Conclusion

4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.

1. **Масштабирование обязательно** — StandardScaler критичен для всех distance-based методов (KMeans, DBSCAN), иначе признаки с большим разбросом доминируют.

2. **Выбор алгоритма зависит от формы кластеров** — KMeans для "шаровидных", DBSCAN для нелинейных и с выбросами.

3. **Silhouette score — хороший критерий** для выбора k, но не единственный. Elbow method и другие метрики дополняют картину.

4. **DBSCAN сложно настраивать** — подбор eps по k-distance графику субъективен, а единый eps не подходит для кластеров разной плотности.

5. **Метрики для DBSCAN считаются на non-noise точках** — нужно явно указывать долю шума и исключать label=-1 из расчёта.

6. **Проверка устойчивости важна** — разные random_state могут давать разные результаты, особенно при нечётких кластерах.

7. **PCA — простой и эффективный способ визуализации** — позволяет увидеть структуру кластеров в 2D, хотя теряется часть информации.

8. **Unsupervised — это эксперимент** — без истинных меток нельзя однозначно сказать, что результат "правильный", только что он согласован с метриками.
