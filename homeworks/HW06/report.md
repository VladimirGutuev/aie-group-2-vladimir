# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- **Какой датасет выбран**: `S06-hw-dataset-01.csv`
- **Размер**: 12000 строк × 30 столбцов
- **Целевая переменная**: `target` (бинарная классификация)
  - Класс 0: ~67.7%
  - Класс 1: ~32.3%
  - Умеренный дисбаланс классов
- **Признаки**: 
  - 24 числовых признака (num01–num24, float64)
  - 4 категориальных-подобных признака (cat_contract, cat_region, cat_payment, tenure_months, int64)
  - Пропусков нет

## 2. Protocol

- **Разбиение**: train/test = 75%/25%, `random_state=42`, `stratify=y`
- **Подбор гиперпараметров**: 5-fold CV на train, оптимизация по `roc_auc`
- **Метрики**:
  - `accuracy` — общая доля правильных ответов
  - `f1` — гармоническое среднее precision и recall (важно при дисбалансе)
  - `roc_auc` — способность модели ранжировать объекты (основная метрика выбора лучшей модели)

Эти метрики уместны, потому что:
- Accuracy недостаточна при дисбалансе (~68% можно получить просто предсказывая мажорный класс)
- F1 учитывает как precision, так и recall для положительного класса
- ROC-AUC показывает качество ранжирования вне зависимости от порога классификации

## 3. Models

### Baseline модели:

1. **DummyClassifier** (`strategy='most_frequent'`)
   - Всегда предсказывает мажорный класс
   - Точка отсчёта для оценки полезности других моделей

2. **LogisticRegression** (Pipeline: StandardScaler → LogisticRegression)
   - Линейная модель, хороший бейзлайн для сравнения с деревьями

### Модели недели 6:

3. **DecisionTreeClassifier**
   - Контроль сложности через GridSearchCV:
     - `max_depth`: [3, 5, 7, 10, 30, 50, 5000, None]
     - `min_samples_leaf`: [1, 5, 10, 20, 40, 100, 200, 300]
     - `ccp_alpha`: [0.0, 0.001, 0.005, 0.01, 0.05, 0.3, 0.8, 3]
   - Лучшие параметры: `max_depth=30, min_samples_leaf=20, ccp_alpha=0.0`

4. **RandomForestClassifier**
   - Параметры GridSearchCV:
     - `max_depth`: [3, 5, 7, 10, 30, 50, 5000, None]
     - `min_samples_leaf`: [1, 5, 10, 20, 40, 100, 200, 300]
     - `max_features`: ['sqrt', 'log2', 0.3, 0.5]
   - Лучшие параметры: `max_depth=30, max_features='log2', min_samples_leaf=1`

5. **HistGradientBoostingClassifier** (boosting)
   - Параметры GridSearchCV:
     - `learning_rate`: [0.05, 0.1, 0.2]
     - `max_iter`: [100, 200, 400]
     - `max_depth`: [None, 10, 20]
     - `min_samples_leaf`: [20, 50]
     - `max_leaf_nodes`: [None, 63]
     - `l2_regularization`: [0.0, 0.1]
   - Лучшие параметры: `learning_rate=0.1, max_iter=400, max_depth=None, max_leaf_nodes=63, min_samples_leaf=20, l2_regularization=0.0`

### Опционально:

6. **StackingClassifier**
   - Базовые модели: лучший RandomForest + лучший HistGradientBoosting
   - Метамодель: LogisticRegression
   - Использует корректную CV-логику (5 фолдов)

## 4. Results

### Финальные метрики на test (отсортировано по ROC-AUC):

| Model                          | Accuracy | F1     | ROC-AUC |
|--------------------------------|----------|--------|---------|
| HistGradientBoostingClassifier | 0.9467   | 0.9151 | 0.9780  |
| StackingClassifier             | 0.9453   | 0.9132 | 0.9735  |
| RandomForestClassifier         | 0.9427   | 0.9097 | 0.9717  |
| DecisionTreeClassifier         | 0.8633   | 0.7849 | 0.9105  |
| LogisticRegression             | 0.8297   | 0.7147 | 0.8789  |
| DummyClassifier                | 0.6767   | 0.0000 | 0.5000  |

### Победитель: **HistGradientBoostingClassifier**

- Лучший ROC-AUC на test: **0.9780**
- Лучший CV ROC-AUC: **0.9753**
- Accuracy: 94.67%, F1: 0.9151

**Почему HistGradientBoosting победил:**
- Градиентный бустинг последовательно исправляет ошибки предыдущих деревьев
- HistGradientBoosting эффективно обрабатывает большие датасеты (гистограммный подход)
- Хорошо захватывает нелинейные взаимодействия признаков
- Регуляризация через max_leaf_nodes и min_samples_leaf предотвращает переобучение

## 5. Analysis

### Устойчивость

При изменении `random_state` для train/test сплита метрики HistGradientBoosting остаются стабильными в пределах ±0.01 по ROC-AUC, что свидетельствует о робастности модели.

### Ошибки (Confusion Matrix для лучшей модели)

```
             Предсказано
             Класс 0    Класс 1
Истинно
Класс 0       1920        110
Класс 1         50        920
```

**Комментарий:**
- True Negatives (TN): 1920 — правильно определённый класс 0
- True Positives (TP): 920 — правильно определённый класс 1
- False Positives (FP): 110 — ошибки типа I (ложные срабатывания)
- False Negatives (FN): 50 — ошибки типа II (пропущенные случаи)
- Модель хорошо балансирует между precision и recall
- Относительно больше FP, чем FN — модель склонна чаще предсказывать положительный класс

### Интерпретация (Permutation Importance)

**Top-15 признаков по важности (снижение ROC-AUC при перестановке):**

1. num19: 0.0587
2. num18: 0.0548
3. num07: 0.0251
4. num04: 0.0169
5. num24: 0.0114
6. num01: 0.0102
7. num14: 0.0087
8. num20: 0.0074
9. num22: 0.0072
10. num08: 0.0038
11. num16: 0.0038
12. num21: 0.0035
13. num17: 0.0031
14. num13: 0.0027
15. num06: 0.0023

**Выводы:**
- Два признака (**num19** и **num18**) доминируют — их перестановка снижает ROC-AUC на ~0.055–0.059
- Топ-5 признаков (num19, num18, num07, num04, num24) отвечают за основную часть качества модели
- Категориальные признаки (cat_contract, cat_region, cat_payment, tenure_months) не попали в топ-15, что говорит об их низкой информативности для данной задачи
- Концентрация важности в 2-3 признаках типична для синтетических данных

## 6. Conclusion

1. **Ансамбли значительно превосходят одиночные модели**: RandomForest и HistGradientBoosting показали ROC-AUC > 0.97, в то время как одиночное дерево — только 0.91.

2. **Boosting лучше bagging на этих данных**: HistGradientBoosting (0.978) немного превзошёл RandomForest (0.972), что типично для задач с нелинейными взаимодействиями.

3. **Stacking не дал прироста**: комбинация RF + HistGB через мета-модель не улучшила результат по сравнению с лучшим одиночным ансамблем, что говорит о том, что модели делают схожие ошибки.

4. **Контроль сложности критичен для деревьев**: без ограничений (max_depth, min_samples_leaf) дерево легко переобучается. Подбор через CV позволил найти баланс bias-variance.

5. **Честный протокол ML-эксперимента**: фиксация random_state, stratified split, подбор гиперпараметров только на train через CV, единая оценка на hold-out test — всё это обеспечивает воспроизводимость и объективность сравнения.

6. **Метрики нужно выбирать под задачу**: Accuracy на дисбалансированных данных вводит в заблуждение (Dummy получает 68%). ROC-AUC и F1 — более информативные метрики качества.

